{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbb9d83-4834-4967-aacc-b1e8545bc441",
   "metadata": {},
   "source": [
    "# Chapitre 2- Analyse exploratoire et pré-traitement de données:\n",
    "\n",
    "> L'apprentissage automatique nécessite de grandes quantités de données , mais les données brutes provenant de diverses sources (audio, vidéo, texte, etc.) ne sont pas directement exploitables. \n",
    "Le prétraitement des données est une étape cruciale qui consiste à nettoyer, transformer et formater ces données afin qu'elles puissent être utilisées efficacement par les algorithmes. Bien que cette phase soit essentielle pour la réussite du projet, elle est souvent la plus longue et complexe.\n",
    "\n",
    "L'objectif principal de ce TP consiste à appliquer deux techniques essentielles de prétraitement:\n",
    "- Nettoyage des données : Comment identifier et gérer les valeurs manquantes et les erreurs.\n",
    "- Transformation des données : Comment ajuster les données pour qu'elles soient prêtes à être analysées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1ba0a-5a06-4fe1-a064-abbcdbc191f6",
   "metadata": {},
   "source": [
    "**Exercice1** : Analyse des Passagers du Titanic\n",
    "\n",
    ">Dans cet exercice, vous allez utiliser le dataset des passagers du Titanic pour appliquer les notions de population, échantillon, et les différents types de variables statistiques.\n",
    "Objectifs :\n",
    "\n",
    ">- Comprendre les concepts de population, échantillon, individus et variables.\n",
    ">- Manipuler des variables qualitatives et quantitatives.\n",
    ">- Explorer les caractéristiques de la population de passagers (via un échantillon).\n",
    ">- Gestion des valeurs manquantes\n",
    "\n",
    "Étapes :\n",
    "\n",
    "1. Charger et explorer les données :\n",
    ">* Utilisez la bibliothèque `seaborn` et la commande `load_dataset('titanic')`  pour charger les données.\n",
    ">* Affichez un échantillon de quelques passagers.\n",
    "\n",
    "2. Identification des types de variables :\n",
    "> * Identifiez quelles colonnes du dataset représentent des variables qualitatives (ordinales/nominales) et quantitatives (discrètes/continues).\n",
    ">* Effectuez des statistiques descriptives sur les variables quantitatives (par exemple : âge, tarif du billet).\n",
    ">* Analysez la répartition des variables qualitatives (par exemple : sexe, classe).\n",
    "\n",
    "3. Gestion des valeurs manquantes :\n",
    ">* Ce dataset contient-il des valeurs manquantes ? Si oui, comptez le nombre de valeurs manquantes par colonne ainsi que le nombre total de valeurs manquantes. Interprétez les résultats.\n",
    ">* Créez un DataFrame `df1` en retirant les observations (lignes) qui contiennent des données manquantes. Calculez la taille de df1.\n",
    ">* Créez un DataFrame `df2` en retirant d'abord la colonne deck, puis en supprimant les observations (lignes) qui contiennent des valeurs manquantes (respectez cet ordre de traitement). Calculez la taille de `df2` et interprétez les résultats.\n",
    ">* Créez un DataFrame `df3` contenant les variables continues `age` et `fare`, puis remplacer les valeurs manquantes de la variable 'age' par sa médiane.\n",
    "\n",
    "\n",
    "4. Normalisation des variables quantitives continues :\n",
    "\n",
    ">* En utilisant ``scikit-learn`` et ``pandas``. Nous allons appliquer une normalisation ``Min-Max`` pour transformer les valeurs de chaque variable de `df3` en des valeurs entre 0 et 1.\n",
    ">> **Remarque:**  Nous utilisons le <code>MinMaxScaler</code> de <code>scikit-learn</code> pour normaliser les caractéristiques de l'ensemble de données. Ce scaler ramène toutes les valeurs dans un intervalle entre 0 et 1 en utilisant la formule suivante:\n",
    ">>> $$X_{normalized} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6defa4-7039-40a5-8d10-32a373dc56fe",
   "metadata": {},
   "source": [
    "**Corrigé:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d30c55-fc80-40f9-ae9c-b73d91b847f1",
   "metadata": {},
   "source": [
    "1. Chargez le dataset des passagers du `Titanic` : Vous pouvez utiliser le dataset disponible via `seaborn` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd1f1d8-5bdd-48d5-ba01-7f1957ae4413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  Gender        Country Occupation self_employed  \\\n",
      "0  8/27/2014 11:29  Female  United States  Corporate           NaN   \n",
      "1  8/27/2014 11:31  Female  United States  Corporate           NaN   \n",
      "2  8/27/2014 11:32  Female  United States  Corporate           NaN   \n",
      "3  8/27/2014 11:37  Female  United States  Corporate            No   \n",
      "4  8/27/2014 11:43  Female  United States  Corporate            No   \n",
      "\n",
      "  family_history treatment Days_Indoors Growing_Stress Changes_Habits  \\\n",
      "0             No       Yes    1-14 days            Yes             No   \n",
      "1            Yes       Yes    1-14 days            Yes             No   \n",
      "2            Yes       Yes    1-14 days            Yes             No   \n",
      "3            Yes       Yes    1-14 days            Yes             No   \n",
      "4            Yes       Yes    1-14 days            Yes             No   \n",
      "\n",
      "  Mental_Health_History Mood_Swings Coping_Struggles Work_Interest  \\\n",
      "0                   Yes      Medium               No            No   \n",
      "1                   Yes      Medium               No            No   \n",
      "2                   Yes      Medium               No            No   \n",
      "3                   Yes      Medium               No            No   \n",
      "4                   Yes      Medium               No            No   \n",
      "\n",
      "  Social_Weakness mental_health_interview care_options  \n",
      "0             Yes                      No     Not sure  \n",
      "1             Yes                      No           No  \n",
      "2             Yes                      No          Yes  \n",
      "3             Yes                   Maybe          Yes  \n",
      "4             Yes                      No          Yes  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le dataset Titanic depuis seaborn\n",
    "titanic = pd.read_csv('D:\\codePack\\OneDrive\\Desktop\\ProjectsClouds\\MentallHealthAwareness\\Mental Health Dataset.csv')\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcbb43",
   "metadata": {},
   "source": [
    "**Aperçu global sur les variables du dataset Titanic**\n",
    "\n",
    "Le dataset Titanic contient des informations sur les passagers du Titanic, souvent utilisé pour l'apprentissage de l'analyse de données et du machine learning. Voici une explication des principales variables.\n",
    "\n",
    "\n",
    "\n",
    "1. **`survived`** (Survécu) :\n",
    "   - **Type** : Quantitatif discret\n",
    "   - **Description** : Indique si le passager a survécu ou non au naufrage.\n",
    "     - 0 = Non (le passager n'a pas survécu)\n",
    "     - 1 = Oui (le passager a survécu)\n",
    "\n",
    "2. **`pclass`** (Classe de billet) :\n",
    "   - **Type** : Qualitatif ordinal\n",
    "   - **Description** : La classe du billet du passager (indicatif de la position sociale).\n",
    "     - 1 = Première classe\n",
    "     - 2 = Deuxième classe\n",
    "     - 3 = Troisième classe\n",
    "\n",
    "3. **`sex`** (Sexe) :\n",
    "   - **Type** : Qualitatif nominal\n",
    "   - **Description** : Le sexe du passager.\n",
    "     - `male` = Homme\n",
    "     - `female` = Femme\n",
    "\n",
    "4. **`age`** (Âge) :\n",
    "   - **Type** : Quantitatif continu\n",
    "   - **Description** : Âge du passager en années. Les valeurs manquantes sont indiquées par `NaN`.\n",
    "\n",
    "5. **`sibsp`** (Nombre de frères et sœurs / conjoints à bord) :\n",
    "   - **Type** : Quantitatif discret\n",
    "   - **Description** : Nombre de frères, sœurs ou conjoints à bord du Titanic.\n",
    "\n",
    "6. **`parch`** (Nombre de parents/enfants à bord) :\n",
    "   - **Type** : Quantitatif discret\n",
    "   - **Description** : Nombre de parents ou enfants à bord du Titanic.\n",
    "\n",
    "7. **`fare`** (Tarif du billet) :\n",
    "   - **Type** : Quantitatif continu\n",
    "   - **Description** : Prix du billet en livres sterling (GBP).\n",
    "\n",
    "8. **`embarked`** (Port d'embarquement) :\n",
    "   - **Type** : Qualitatif nominal\n",
    "   - **Description** : Port où le passager a embarqué.\n",
    "     - `C` = Cherbourg\n",
    "     - `Q` = Queenstown\n",
    "     - `S` = Southampton\n",
    "\n",
    "9. **`class`** (Classe du passager) :\n",
    "   - **Type** : Qualitatif ordinal\n",
    "   - **Description** : Version textuelle de la variable `pclass`.\n",
    "     - `First` = Première classe\n",
    "     - `Second` = Deuxième classe\n",
    "     - `Third` = Troisième classe\n",
    "\n",
    "10. **`who`** (Catégorie de personne) :\n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Catégorie de la personne (homme, femme, enfant).\n",
    "      - `man` = Homme adulte\n",
    "      - `woman` = Femme adulte\n",
    "      - `child` = Enfant\n",
    "\n",
    "11. **`deck`** (Pont du bateau) :\n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Pont sur lequel se trouvait la cabine du passager. Valeurs manquantes pour certains passagers.\n",
    "\n",
    "12. **`embark_town`** (Ville d'embarquement) :\n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Ville depuis laquelle le passager a embarqué.\n",
    "      - `Cherbourg`, `Queenstown`, `Southampton`\n",
    "\n",
    "13. **`alive`** (Survivant) :\n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Version textuelle de `survived`.\n",
    "      - `yes` = Le passager a survécu\n",
    "      - `no` = Le passager n'a pas survécu\n",
    "\n",
    "14. **`alone`** (Seul à bord) :\n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Indique si le passager était seul à bord.\n",
    "      - `True` = Seul\n",
    "      - `False` = Avec famille\n",
    "\n",
    "\n",
    "15. **`ticket`** (Numéro de billet) :  \n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Numéro de billet du passager.\n",
    "  \n",
    "16. **`cabin`** (Numéro de cabine) :  \n",
    "    - **Type** : Qualitatif nominal\n",
    "    - **Description** : Numéro de cabine du passager (beaucoup de valeurs manquantes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf7fea-ede3-4d23-97b5-614fd1c89222",
   "metadata": {},
   "source": [
    "2. Identification des types de variables :Identifiez quelles colonnes du dataset représentent des variables qualitatives (ordinales/nominales) et quantitatives (discrètes/continues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ccc5f8-0fdb-4939-a1b6-426daaee247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp', 'Gender', 'Country', 'Occupation', 'self_employed',\n",
      "       'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress',\n",
      "       'Changes_Habits', 'Mental_Health_History', 'Mood_Swings',\n",
      "       'Coping_Struggles', 'Work_Interest', 'Social_Weakness',\n",
      "       'mental_health_interview', 'care_options'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##Afficher les colonnes de dataset\n",
    "print(titanic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f999c7-1947-4b79-8ef8-68e42a4fd922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                  object\n",
      "Gender                     object\n",
      "Country                    object\n",
      "Occupation                 object\n",
      "self_employed              object\n",
      "family_history             object\n",
      "treatment                  object\n",
      "Days_Indoors               object\n",
      "Growing_Stress             object\n",
      "Changes_Habits             object\n",
      "Mental_Health_History      object\n",
      "Mood_Swings                object\n",
      "Coping_Struggles           object\n",
      "Work_Interest              object\n",
      "Social_Weakness            object\n",
      "mental_health_interview    object\n",
      "care_options               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#afficher le type de chaque colonne\n",
    "print(titanic.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd4c703f-94e7-4ab8-b3ff-11abb718eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les colonnes en qualitatives et quantitatives\n",
    "# Séparer les colonnes en qualitatives et quantitatives\n",
    "qualitative_vars = ['sex', 'embarked', 'class', 'who', 'deck', 'embark_town', 'alive', 'alone']\n",
    "quantitative_vars = ['age', 'fare', 'sibsp', 'parch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6eedfa6c-d528-48be-9e09-da74bdb98f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modalités pour la variable 'sex':\n",
      "['male' 'female']\n",
      "\n",
      "Modalités pour la variable 'embarked':\n",
      "['S' 'C' 'Q' nan]\n",
      "\n",
      "Modalités pour la variable 'class':\n",
      "['Third', 'First', 'Second']\n",
      "Categories (3, object): ['First', 'Second', 'Third']\n",
      "\n",
      "Modalités pour la variable 'who':\n",
      "['man' 'woman' 'child']\n",
      "\n",
      "Modalités pour la variable 'deck':\n",
      "[NaN, 'C', 'E', 'G', 'D', 'A', 'B', 'F']\n",
      "Categories (7, object): ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "\n",
      "Modalités pour la variable 'embark_town':\n",
      "['Southampton' 'Cherbourg' 'Queenstown' nan]\n",
      "\n",
      "Modalités pour la variable 'alive':\n",
      "['no' 'yes']\n",
      "\n",
      "Modalités pour la variable 'alone':\n",
      "[False  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher les modalités pour chaque variable catégorielle\n",
    "for var in qualitative_vars:\n",
    "    print(f\"Modalités pour la variable '{var}':\")\n",
    "    print(titanic[var].unique())\n",
    "    print()  # Ligne vide pour séparer les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "21864efa-dc9d-4372-9d8f-e818e901c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition de sex :\n",
      "male      577\n",
      "female    314\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de embarked :\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: embarked, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de class :\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: class, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de who :\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: who, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de deck :\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: deck, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de embark_town :\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: embark_town, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de alive :\n",
      "no     549\n",
      "yes    342\n",
      "Name: alive, dtype: int64\n",
      "\n",
      "\n",
      "Répartition de alone :\n",
      "True     537\n",
      "False    354\n",
      "Name: alone, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Répartition des variables qualitatives\n",
    "for var in qualitative_vars:\n",
    "    print(f\"Répartition de {var} :\")\n",
    "    print(titanic[var].value_counts())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3d80f6-7919-4d29-87f1-db01509f3e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantitative_vars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Description des variables quantitatives\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(titanic[\u001b[43mquantitative_vars\u001b[49m]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'quantitative_vars' is not defined"
     ]
    }
   ],
   "source": [
    "# Description des variables quantitatives\n",
    "print(titanic[quantitative_vars].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0df3a-ee3f-47bb-9000-b0166891a278",
   "metadata": {},
   "source": [
    "3. Gestion des valeurs manquantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8110b1a2-f692-4b8d-8f56-8844f656f938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ce dataset contient-il des valeurs manquantes ? comptez le nombre de valeurs manquantes par colonne \n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4af50c9b-10c6-48ff-b1b4-412aa350c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le nombre total de valeurs manquantes. Interprétez les résultats.\n",
    "titanic.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9af4d93f-eb17-4768-9470-5cd63d0b8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 15)\n"
     ]
    }
   ],
   "source": [
    "#  Créez un DataFrame df1 en retirant les observations (lignes) qui contiennent des données manquantes. Calculez la taille de df1.\n",
    "df1 = titanic.dropna()\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27a801ce-781a-4d3a-8334-402d4664ef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créez un DataFrame `df2` en retirant d'abord la colonne deck, puis en supprimant les observations (lignes) qui contiennent des valeurs manquantes (respectez cet ordre de traitement). Calculez la taille de `df2` et interprétez les résultats.\n",
    "\n",
    "df2 = titanic.drop('deck', axis=1).dropna()\n",
    "print(df2.shape)\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc6de2-6f6e-4ea1-8f92-2a41bae6db73",
   "metadata": {},
   "source": [
    "**Bien qu'il soit généralement conseillé d'éviter de supprimer des colonnes entières, cela peut parfois être nécessaire. Dans notre cas, après avoir supprimé certaines observations (lignes), la taille de df1 est de 182 sur 891. En supprimant la colonne deck, puis en éliminant les lignes contenant des valeurs manquantes, nous obtenons un nouveau DataFrame df2 de taille 712 sur 891. Pour cela, l'analyse exploratoire des données est importante, car chaque dataset a ses propres spécificités.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "51c72e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#créer un dataframe contenant les variables age et fare\n",
    "df3=titanic[['age','fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b620e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#remplacer les valeurs manquantes de la variable age par sa médiane\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m median \u001b[38;5;241m=\u001b[39m df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian() \n\u001b[0;32m      3\u001b[0m df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(median, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m df3\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df3' is not defined"
     ]
    }
   ],
   "source": [
    "#remplacer les valeurs manquantes de la variable age par sa médiane\n",
    "median = df3['age'].median() \n",
    "df3['age'].fillna(median, inplace=True)\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f3aae",
   "metadata": {},
   "source": [
    "4. Normalisation des variables quantitives continues :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9bec5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer et instancier MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc2610b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.025374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.058556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.346569</td>\n",
       "      <td>0.045771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.058556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    0.271174  0.014151\n",
       "1    0.472229  0.139136\n",
       "2    0.321438  0.015469\n",
       "3    0.434531  0.103644\n",
       "4    0.434531  0.015713\n",
       "..        ...       ...\n",
       "886  0.334004  0.025374\n",
       "887  0.233476  0.058556\n",
       "888  0.346569  0.045771\n",
       "889  0.321438  0.058556\n",
       "890  0.396833  0.015127\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appliquer MinMaxScaler sur df3\n",
    "scaler_fit=scaler.fit_transform(df3)\n",
    "df3_scaled = pd.DataFrame(scaler_fit)\n",
    "df3_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c0989-a50b-4caf-99c0-40fe3d711857",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b1355e4-70fc-4b98-b73b-73849dbab065",
   "metadata": {},
   "source": [
    "**Exercice 2:**\n",
    ">Le dataset ``flights`` dans ``seaborn`` contient des informations mensuelles sur le nombre de passagers aériens de 1949 à 1960. Nous allons appliquer un encodage One-Hot Encoding sur la colonne des mois (month), qui est une variable catégorielle.\n",
    ">> **Remarque :** Nous utilisons ``OneHotEncoder`` de ``scikit-learn`` pour transformer la colonne ``Month`` en plusieurs colonnes binaires. Chaque colonne correspond à un mois (par exemple, \"Month_Jan\", \"Month_Feb\", etc.), et chaque ligne indique si le mois en question est présent (1) ou non (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "445c1c79-f186-48f9-b9ee-066a7d6395fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b8425d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset avant One-Hot Encoding :\n",
      "   year month  passengers\n",
      "0  1949   Jan         112\n",
      "1  1949   Feb         118\n",
      "2  1949   Mar         132\n",
      "3  1949   Apr         129\n",
      "4  1949   May         121\n"
     ]
    }
   ],
   "source": [
    "# Charger le dataset flights de seaborn\n",
    "df = sns.load_dataset('flights')\n",
    "\n",
    "# Affichage des premières lignes du DataFrame original\n",
    "print(\"Dataset avant One-Hot Encoding :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fbaeedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du One-Hot Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a9a823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du One-Hot Encoding sur la colonne 'month'\n",
    "one_hot_encoded = encoder.fit_transform(df[['month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "337da6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Affichage de one_hot_encoded et de son type\n",
    "print(one_hot_encoded,type(one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb9a2eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(one_hot_encoded,type(one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "978d0129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_Apr</th>\n",
       "      <th>month_Aug</th>\n",
       "      <th>month_Dec</th>\n",
       "      <th>month_Feb</th>\n",
       "      <th>month_Jan</th>\n",
       "      <th>month_Jul</th>\n",
       "      <th>month_Jun</th>\n",
       "      <th>month_Mar</th>\n",
       "      <th>month_May</th>\n",
       "      <th>month_Nov</th>\n",
       "      <th>month_Oct</th>\n",
       "      <th>month_Sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_Apr  month_Aug  month_Dec  month_Feb  month_Jan  month_Jul  \\\n",
       "0          0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "1          0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "2          0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3          1.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4          0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "139        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "140        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "141        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "142        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "143        0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "\n",
       "     month_Jun  month_Mar  month_May  month_Nov  month_Oct  month_Sep  \n",
       "0          0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1          0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "2          0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "3          0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4          0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "139        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "140        0.0        0.0        0.0        0.0        0.0        1.0  \n",
       "141        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "142        0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "143        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[144 rows x 12 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'un DataFrame des colonnes encodées\n",
    "encoded_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(['month']))\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bce1fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les colonnes encodées avec le DataFrame original sans la variable 'month'\n",
    "df_encoded = pd.concat([df.drop('month', axis=1), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6aee6d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset après One-Hot Encoding :\n",
      "   year  passengers  month_Apr  month_Aug  month_Dec  month_Feb  month_Jan  \\\n",
      "0  1949         112        0.0        0.0        0.0        0.0        1.0   \n",
      "1  1949         118        0.0        0.0        0.0        1.0        0.0   \n",
      "2  1949         132        0.0        0.0        0.0        0.0        0.0   \n",
      "3  1949         129        1.0        0.0        0.0        0.0        0.0   \n",
      "4  1949         121        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   month_Jul  month_Jun  month_Mar  month_May  month_Nov  month_Oct  month_Sep  \n",
      "0        0.0        0.0        0.0        0.0        0.0        0.0        0.0  \n",
      "1        0.0        0.0        0.0        0.0        0.0        0.0        0.0  \n",
      "2        0.0        0.0        1.0        0.0        0.0        0.0        0.0  \n",
      "3        0.0        0.0        0.0        0.0        0.0        0.0        0.0  \n",
      "4        0.0        0.0        0.0        1.0        0.0        0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "# Affichage du DataFrame après One-Hot Encoding\n",
    "print(\"\\nDataset après One-Hot Encoding :\")\n",
    "print(df_encoded.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
