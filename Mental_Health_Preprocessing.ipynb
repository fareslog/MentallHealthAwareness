{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapitre 2 - Analyse exploratoire et pré-traitement de données\n",
        "\n",
        "L'apprentissage automatique nécessite de grandes quantités de données, mais les données brutes provenant de diverses sources (audio, vidéo, texte, etc.) ne sont pas directement exploitables. Le prétraitement des données est une étape cruciale qui consiste à nettoyer, transformer et formater ces données afin qu'elles puissent être utilisées efficacement par les algorithmes. Bien que cette phase soit essentielle pour la réussite du projet, elle est souvent la plus longue et complexe.\n",
        "\n",
        "L'objectif principal de ce TP consiste à appliquer deux techniques essentielles de prétraitement :\n",
        "- Nettoyage des données : Identifier et gérer les valeurs manquantes et les erreurs.\n",
        "- Transformation des données : Ajuster les données pour qu'elles soient prêtes à être analysées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 1: Analyse du Mental Health Dataset\n",
        "\n",
        "Dans cet exercice, vous allez utiliser le \"Mental Health Dataset\" pour appliquer les notions de population, échantillon, et les différents types de variables statistiques.\n",
        "\n",
        "**Objectifs** :\n",
        "- Comprendre les concepts de population, échantillon, individus et variables.\n",
        "- Manipuler des variables qualitatives et quantitatives.\n",
        "- Explorer les caractéristiques de la population (via un échantillon).\n",
        "- Gérer les valeurs manquantes.\n",
        "- Appliquer des transformations comme l'encodage des variables catégoriques.\n",
        "\n",
        "**Étapes** :\n",
        "1. Charger et explorer les données :\n",
        "   - Charger le dataset depuis le fichier CSV spécifié.\n",
        "   - Afficher un échantillon de quelques observations.\n",
        "2. Identification des types de variables :\n",
        "   - Identifier les colonnes qualitatives (nominales/ordinales) et quantitatives (s’il y en a).\n",
        "   - Effectuer des statistiques descriptives sur les variables.\n",
        "   - Analyser la répartition des variables qualitatives.\n",
        "3. Gestion des valeurs manquantes :\n",
        "   - Vérifier la présence de valeurs manquantes et les compter par colonne.\n",
        "   - Créer un DataFrame `df1` en supprimant les lignes avec des valeurs manquantes.\n",
        "   - Créer un DataFrame `df2` en supprimant les lignes avec des valeurs manquantes (aucune colonne à supprimer, car pas de colonne équivalente à `deck`).\n",
        "   - Créer un DataFrame `df3` avec une variable (e.g., `self_employed`) et imputer les valeurs manquantes par la mode.\n",
        "4. Encodage des variables qualitatives :\n",
        "   - Appliquer un encodage one-hot sur les variables catégoriques nominales (e.g., `Gender`, `Country`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Charger le dataset\n",
        "\n",
        "Charger le \"Mental Health Dataset\" depuis le fichier CSV spécifié et afficher les premières lignes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3500, 14)\n",
            "First 5 rows of the dataset:\n",
            "   User_ID  Age  Gender Education_Level Employment_Status  Work_Hours_Week  \\\n",
            "0     1001   35  Female      University          Employed        50.790616   \n",
            "1     1002   28    Male      University        Unemployed         0.000000   \n",
            "2     1003   37   Other      University        Unemployed         0.000000   \n",
            "3     1004   48  Female      University     Self-employed        80.000000   \n",
            "4     1005   27    Male      University          Employed        49.670909   \n",
            "\n",
            "   Sleep_Hours_Night  Exercise_Freq_Week Social_Support  GAD-7_Score  \\\n",
            "0           3.573649                 4.0            Low            7   \n",
            "1           6.127009                 1.0            Low            8   \n",
            "2           5.571812                 2.0         Medium            6   \n",
            "3           6.721314                 2.0            Low            9   \n",
            "4           7.754259                 3.0            Low            7   \n",
            "\n",
            "   PHQ-9_Score  Stress_Level_Scale Coping_Mechanism Risk_Level  \n",
            "0           22                 8.0      Socializing     Medium  \n",
            "1            3                 4.0             Work        Low  \n",
            "2           12                 4.0           Gaming     Medium  \n",
            "3           14                 5.0           Gaming     Medium  \n",
            "4           17                 8.0        Isolation     Medium  \n",
            "User_ID                 int64\n",
            "Age                     int64\n",
            "Gender                 object\n",
            "Education_Level        object\n",
            "Employment_Status      object\n",
            "Work_Hours_Week       float64\n",
            "Sleep_Hours_Night     float64\n",
            "Exercise_Freq_Week    float64\n",
            "Social_Support         object\n",
            "GAD-7_Score             int64\n",
            "PHQ-9_Score             int64\n",
            "Stress_Level_Scale    float64\n",
            "Coping_Mechanism       object\n",
            "Risk_Level             object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Charger le dataset depuis le fichier CSV\n",
        "data = pd.read_csv('D:\\\\codePack\\\\OneDrive\\\\Desktop\\\\ProjectsClouds\\\\MentallHealthAwareness\\\\HealthMind_Mental_Health_Data_3500.csv')\n",
        "df_processed = data.copy()\n",
        "print(data.shape)\n",
        "# Afficher les premières lignes\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "print(data.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Explorer les données\n",
        "\n",
        "Examiner la structure du dataset, les types de données, et les statistiques descriptives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valeurs manquantes par colonne:\n",
            "Education_Level       245\n",
            "Work_Hours_Week       245\n",
            "Sleep_Hours_Night     245\n",
            "Exercise_Freq_Week    245\n",
            "Stress_Level_Scale    245\n",
            "Coping_Mechanism      245\n",
            "dtype: int64\n",
            "\n",
            "Colonnes du dataset:\n",
            "Index(['User_ID', 'Age', 'Gender', 'Education_Level', 'Employment_Status',\n",
            "       'Work_Hours_Week', 'Sleep_Hours_Night', 'Exercise_Freq_Week',\n",
            "       'Social_Support', 'GAD-7_Score', 'PHQ-9_Score', 'Stress_Level_Scale',\n",
            "       'Coping_Mechanism', 'Risk_Level'],\n",
            "      dtype='object')\n",
            "\n",
            "Types de données:\n",
            "User_ID                 int64\n",
            "Age                     int64\n",
            "Gender                 object\n",
            "Education_Level        object\n",
            "Employment_Status      object\n",
            "Work_Hours_Week       float64\n",
            "Sleep_Hours_Night     float64\n",
            "Exercise_Freq_Week    float64\n",
            "Social_Support         object\n",
            "GAD-7_Score             int64\n",
            "PHQ-9_Score             int64\n",
            "Stress_Level_Scale    float64\n",
            "Coping_Mechanism       object\n",
            "Risk_Level             object\n",
            "dtype: object\n",
            "\n",
            "Statistiques descriptives:\n",
            "            User_ID          Age  Gender Education_Level Employment_Status  \\\n",
            "count   3500.000000  3500.000000    3500            3255              3500   \n",
            "unique          NaN          NaN       4               4                 5   \n",
            "top             NaN          NaN  Female      University          Employed   \n",
            "freq            NaN          NaN    1623            1506              1776   \n",
            "mean    2750.500000    30.797143     NaN             NaN               NaN   \n",
            "std     1010.507298    10.328942     NaN             NaN               NaN   \n",
            "min     1001.000000    18.000000     NaN             NaN               NaN   \n",
            "25%     1875.750000    22.000000     NaN             NaN               NaN   \n",
            "50%     2750.500000    30.000000     NaN             NaN               NaN   \n",
            "75%     3625.250000    38.000000     NaN             NaN               NaN   \n",
            "max     4500.000000    70.000000     NaN             NaN               NaN   \n",
            "\n",
            "        Work_Hours_Week  Sleep_Hours_Night  Exercise_Freq_Week Social_Support  \\\n",
            "count       3255.000000        3255.000000         3255.000000           3500   \n",
            "unique              NaN                NaN                 NaN              4   \n",
            "top                 NaN                NaN                 NaN         Medium   \n",
            "freq                NaN                NaN                 NaN           1413   \n",
            "mean          31.597232           6.467704            3.011674            NaN   \n",
            "std           21.170626           1.437417            1.980045            NaN   \n",
            "min            0.000000           3.000000            0.000000            NaN   \n",
            "25%           12.000000           5.482000            1.000000            NaN   \n",
            "50%           36.394761           6.472725            3.000000            NaN   \n",
            "75%           48.390009           7.451797            5.000000            NaN   \n",
            "max           80.000000          10.000000            6.000000            NaN   \n",
            "\n",
            "        GAD-7_Score  PHQ-9_Score  Stress_Level_Scale Coping_Mechanism  \\\n",
            "count   3500.000000  3500.000000         3255.000000             3255   \n",
            "unique          NaN          NaN                 NaN                7   \n",
            "top             NaN          NaN                 NaN        Isolation   \n",
            "freq            NaN          NaN                 NaN              690   \n",
            "mean      10.601714    13.769143            4.429186              NaN   \n",
            "std        6.338386     8.163054            2.280663              NaN   \n",
            "min        0.000000     0.000000            1.000000              NaN   \n",
            "25%        5.000000     7.000000            2.000000              NaN   \n",
            "50%       10.000000    14.000000            4.000000              NaN   \n",
            "75%       16.000000    21.000000            6.000000              NaN   \n",
            "max       21.000000    27.000000            8.000000              NaN   \n",
            "\n",
            "       Risk_Level  \n",
            "count        3500  \n",
            "unique          3  \n",
            "top        Medium  \n",
            "freq         1795  \n",
            "mean          NaN  \n",
            "std           NaN  \n",
            "min           NaN  \n",
            "25%           NaN  \n",
            "50%           NaN  \n",
            "75%           NaN  \n",
            "max           NaN  \n",
            "\n",
            "==================================================\n",
            "--- Step 2: Explorer les données ---\n",
            "\n",
            "Types de données:\n",
            "User_ID                 int64\n",
            "Age                     int64\n",
            "Gender                 object\n",
            "Education_Level        object\n",
            "Employment_Status      object\n",
            "Work_Hours_Week       float64\n",
            "Sleep_Hours_Night     float64\n",
            "Exercise_Freq_Week    float64\n",
            "Social_Support         object\n",
            "GAD-7_Score             int64\n",
            "PHQ-9_Score             int64\n",
            "Stress_Level_Scale    float64\n",
            "Coping_Mechanism       object\n",
            "Risk_Level             object\n",
            "dtype: object\n",
            "\n",
            "Statistiques descriptives (incluant les NaN et les catégories):\n",
            "            User_ID          Age  Gender Education_Level Employment_Status  \\\n",
            "count   3500.000000  3500.000000    3500            3255              3500   \n",
            "unique          NaN          NaN       4               4                 5   \n",
            "top             NaN          NaN  Female      University          Employed   \n",
            "freq            NaN          NaN    1623            1506              1776   \n",
            "mean    2750.500000    30.797143     NaN             NaN               NaN   \n",
            "std     1010.507298    10.328942     NaN             NaN               NaN   \n",
            "min     1001.000000    18.000000     NaN             NaN               NaN   \n",
            "25%     1875.750000    22.000000     NaN             NaN               NaN   \n",
            "50%     2750.500000    30.000000     NaN             NaN               NaN   \n",
            "75%     3625.250000    38.000000     NaN             NaN               NaN   \n",
            "max     4500.000000    70.000000     NaN             NaN               NaN   \n",
            "\n",
            "        Work_Hours_Week  Sleep_Hours_Night  Exercise_Freq_Week Social_Support  \\\n",
            "count       3255.000000        3255.000000         3255.000000           3500   \n",
            "unique              NaN                NaN                 NaN              4   \n",
            "top                 NaN                NaN                 NaN         Medium   \n",
            "freq                NaN                NaN                 NaN           1413   \n",
            "mean          31.597232           6.467704            3.011674            NaN   \n",
            "std           21.170626           1.437417            1.980045            NaN   \n",
            "min            0.000000           3.000000            0.000000            NaN   \n",
            "25%           12.000000           5.482000            1.000000            NaN   \n",
            "50%           36.394761           6.472725            3.000000            NaN   \n",
            "75%           48.390009           7.451797            5.000000            NaN   \n",
            "max           80.000000          10.000000            6.000000            NaN   \n",
            "\n",
            "        GAD-7_Score  PHQ-9_Score  Stress_Level_Scale Coping_Mechanism  \\\n",
            "count   3500.000000  3500.000000         3255.000000             3255   \n",
            "unique          NaN          NaN                 NaN                7   \n",
            "top             NaN          NaN                 NaN        Isolation   \n",
            "freq            NaN          NaN                 NaN              690   \n",
            "mean      10.601714    13.769143            4.429186              NaN   \n",
            "std        6.338386     8.163054            2.280663              NaN   \n",
            "min        0.000000     0.000000            1.000000              NaN   \n",
            "25%        5.000000     7.000000            2.000000              NaN   \n",
            "50%       10.000000    14.000000            4.000000              NaN   \n",
            "75%       16.000000    21.000000            6.000000              NaN   \n",
            "max       21.000000    27.000000            8.000000              NaN   \n",
            "\n",
            "       Risk_Level  \n",
            "count        3500  \n",
            "unique          3  \n",
            "top        Medium  \n",
            "freq         1795  \n",
            "mean          NaN  \n",
            "std           NaN  \n",
            "min           NaN  \n",
            "25%           NaN  \n",
            "50%           NaN  \n",
            "75%           NaN  \n",
            "max           NaN  \n",
            "\n",
            "Statistiques sur les scores cliniques:\n",
            "       GAD-7_Score  PHQ-9_Score\n",
            "count  3500.000000  3500.000000\n",
            "mean     10.601714    13.769143\n",
            "std       6.338386     8.163054\n",
            "min       0.000000     0.000000\n",
            "25%       5.000000     7.000000\n",
            "50%      10.000000    14.000000\n",
            "75%      16.000000    21.000000\n",
            "max      21.000000    27.000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Valeurs manquantes par colonne:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Afficher les colonnes du dataset\n",
        "print(\"\\nColonnes du dataset:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Afficher les types de chaque colonne\n",
        "print(\"\\nTypes de données:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# Statistiques descriptives pour toutes les colonnes\n",
        "print(\"\\nStatistiques descriptives:\")\n",
        "print(data.describe(include='all'))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 2: Explorer les données ---\")\n",
        "\n",
        "# 2.2 Data Types: Afficher les types de chaque colonne\n",
        "print(\"\\nTypes de données:\")\n",
        "print(df_processed.dtypes)\n",
        "\n",
        "# 2.3 Statistics: Statistiques descriptives pour toutes les colonnes\n",
        "print(\"\\nStatistiques descriptives (incluant les NaN et les catégories):\")\n",
        "print(df_processed.describe(include='all'))\n",
        "\n",
        "# Exploration spécifique des variables GAD-7 et PHQ-9\n",
        "print(\"\\nStatistiques sur les scores cliniques:\")\n",
        "print(df_processed[['GAD-7_Score', 'PHQ-9_Score']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Identification des types de variables\n",
        "\n",
        "Identifier les variables qualitatives (nominales/ordinales) et quantitatives (s’il y en a). Toutes les colonnes semblent être qualitatives (catégoriques) sauf potentiellement `Timestamp`, qui peut être converti en une variable quantitative si nécessaire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "--- Step 3: Identification des types de variables ---\n",
            "Variables Nominales (pour One-Hot Encoding): ['Gender', 'Employment_Status', 'Coping_Mechanism']\n",
            "Variables Ordinales (pour Mapping): ['Education_Level', 'Social_Support', 'Risk_Level']\n",
            "Variables Quantitatives (pour Scaling): ['Age', 'Work_Hours_Week', 'Sleep_Hours_Night', 'Exercise_Freq_Week', 'GAD-7_Score', 'PHQ-9_Score', 'Stress_Level_Scale']\n",
            "\n",
            "Modalités des variables Nominal/Ordinales (pour vérification):\n",
            "   Gender: ['Female' 'Male' 'Other' 'Non-binary']\n",
            "   Employment_Status: ['Employed' 'Unemployed' 'Self-employed' 'Student' 'Retired']\n",
            "   Coping_Mechanism: ['Socializing' 'Work' 'Gaming' 'Isolation' 'Exercise' 'Mindfulness'\n",
            " 'Reading' nan]\n",
            "   Education_Level: ['University' 'Ph.D.' 'High School' 'Masters' nan]\n",
            "   Social_Support: ['Low' 'Medium' 'Very Low' 'High']\n",
            "   Risk_Level: ['Medium' 'Low' 'High']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 3: Identification des types de variables ---\")\n",
        "\n",
        "# Variables Ordinales: Ont un ordre clair.\n",
        "ordinal_vars = ['Education_Level', 'Social_Support', 'Risk_Level'] \n",
        "# Variables Nominales: Catégories sans ordre.\n",
        "nominal_vars = ['Gender', 'Employment_Status', 'Coping_Mechanism']\n",
        "# Variables Quantitatives: Numériques.\n",
        "quantitative_vars = ['Age', 'Work_Hours_Week', 'Sleep_Hours_Night', 'Exercise_Freq_Week', \n",
        "                     'GAD-7_Score', 'PHQ-9_Score', 'Stress_Level_Scale']\n",
        "# ID à supprimer\n",
        "id_var = ['User_ID']\n",
        "\n",
        "print(f\"Variables Nominales (pour One-Hot Encoding): {nominal_vars}\")\n",
        "print(f\"Variables Ordinales (pour Mapping): {ordinal_vars}\")\n",
        "print(f\"Variables Quantitatives (pour Scaling): {quantitative_vars}\")\n",
        "\n",
        "# Afficher les modalités des variables nominales pour vérifier\n",
        "print(\"\\nModalités des variables Nominal/Ordinales (pour vérification):\")\n",
        "for var in nominal_vars + ordinal_vars:\n",
        "    print(f\"   {var}: {df_processed[var].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Gestion des valeurs manquantes\n",
        "\n",
        "Vérifier les valeurs manquantes, créer des DataFrames en supprimant ou imputant les valeurs manquantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "--- Step 4: Gestion des valeurs manquantes (Imputation) ---\n",
            "\n",
            "Valeurs manquantes avant imputation:\n",
            "Education_Level       245\n",
            "Work_Hours_Week       245\n",
            "Sleep_Hours_Night     245\n",
            "Exercise_Freq_Week    245\n",
            "Stress_Level_Scale    245\n",
            "Coping_Mechanism      245\n",
            "dtype: int64\n",
            "-> Imputation des variables catégoriques/discrètes par la Mode...\n",
            "-> Imputation des variables continues par la Médiane...\n",
            "\n",
            "Valeurs manquantes après imputation (doit être 0 pour les colonnes traitées):\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 4: Gestion des valeurs manquantes (Imputation) ---\")\n",
        "\n",
        "# 4.1 Check NaN: Compter les valeurs manquantes\n",
        "missing_values_count = df_processed.isnull().sum()\n",
        "print(\"\\nValeurs manquantes avant imputation:\")\n",
        "print(missing_values_count[missing_values_count > 0])\n",
        "\n",
        "# 4.2 Impute Mode: Imputation par la Mode (pour les catégories et les variables discrètes)\n",
        "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
        "mode_cols = ['Education_Level', 'Exercise_Freq_Week', 'Coping_Mechanism', 'Stress_Level_Scale']\n",
        "\n",
        "print(\"-> Imputation des variables catégoriques/discrètes par la Mode...\")\n",
        "for col in mode_cols:\n",
        "    # On utilise fit_transform uniquement sur la colonne elle-même\n",
        "    df_processed[col] = imputer_mode.fit_transform(df_processed[[col]])[:, 0]\n",
        "\n",
        "# 4.3 Impute Median: Imputation par la Médiane (pour les variables continues)\n",
        "imputer_median = SimpleImputer(strategy='median')\n",
        "median_cols = ['Work_Hours_Week', 'Sleep_Hours_Night']\n",
        "\n",
        "print(\"-> Imputation des variables continues par la Médiane...\")\n",
        "for col in median_cols:\n",
        "    df_processed[col] = imputer_median.fit_transform(df_processed[[col]])[:, 0]\n",
        "\n",
        "# 4.4 Verification: Confirmer que toutes les valeurs manquantes ont été traitées\n",
        "print(\"\\nValeurs manquantes après imputation (doit être 0 pour les colonnes traitées):\")\n",
        "print(df_processed.isnull().sum().max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Encodage des variables qualitatives\n",
        "\n",
        "Appliquer un encodage one-hot sur les variables catégoriques nominales (e.g., `Gender`, `Country`, `Occupation`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "--- Step 5: Encodage des variables qualitatives ---\n",
            "-> Encodage Ordinal...\n",
            "-> One-Hot Encoding des variables Nominales...\n",
            "\n",
            "Premières 5 lignes après encodage (vérifiez les nouvelles colonnes):\n",
            "   Age  Work_Hours_Week  Sleep_Hours_Night  Exercise_Freq_Week  GAD-7_Score  \\\n",
            "0   35        50.790616           3.573649                 4.0            7   \n",
            "1   28         0.000000           6.127009                 1.0            8   \n",
            "2   37         0.000000           5.571812                 2.0            6   \n",
            "3   48        80.000000           6.721314                 2.0            9   \n",
            "4   27        49.670909           7.754259                 3.0            7   \n",
            "\n",
            "   PHQ-9_Score  Stress_Level_Scale  Education_Level_Encoded  \\\n",
            "0           22                 8.0                        2   \n",
            "1            3                 4.0                        2   \n",
            "2           12                 4.0                        2   \n",
            "3           14                 5.0                        2   \n",
            "4           17                 8.0                        2   \n",
            "\n",
            "   Social_Support_Encoded  Risk_Level_Encoded  ...  Employment_Status_Retired  \\\n",
            "0                       2                   1  ...                      False   \n",
            "1                       2                   0  ...                      False   \n",
            "2                       3                   1  ...                      False   \n",
            "3                       2                   1  ...                      False   \n",
            "4                       2                   1  ...                      False   \n",
            "\n",
            "   Employment_Status_Self-employed  Employment_Status_Student  \\\n",
            "0                            False                      False   \n",
            "1                            False                      False   \n",
            "2                            False                      False   \n",
            "3                             True                      False   \n",
            "4                            False                      False   \n",
            "\n",
            "   Employment_Status_Unemployed  Coping_Mechanism_Gaming  \\\n",
            "0                         False                    False   \n",
            "1                          True                    False   \n",
            "2                          True                     True   \n",
            "3                         False                     True   \n",
            "4                         False                    False   \n",
            "\n",
            "   Coping_Mechanism_Isolation  Coping_Mechanism_Mindfulness  \\\n",
            "0                       False                         False   \n",
            "1                       False                         False   \n",
            "2                       False                         False   \n",
            "3                       False                         False   \n",
            "4                        True                         False   \n",
            "\n",
            "   Coping_Mechanism_Reading  Coping_Mechanism_Socializing  \\\n",
            "0                     False                          True   \n",
            "1                     False                         False   \n",
            "2                     False                         False   \n",
            "3                     False                         False   \n",
            "4                     False                         False   \n",
            "\n",
            "   Coping_Mechanism_Work  \n",
            "0                  False  \n",
            "1                   True  \n",
            "2                  False  \n",
            "3                  False  \n",
            "4                  False  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "Taille après encodage: (3500, 23)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 5: Encodage des variables qualitatives ---\")\n",
        "\n",
        "# 5.1 Ordinal Encoding: Mappage des variables Ordinales (preservation de l'ordre)\n",
        "print(\"-> Encodage Ordinal...\")\n",
        "\n",
        "# Education Level Mapping\n",
        "edu_mapping = {'High School': 1, 'University': 2, 'Masters': 3, 'Ph.D.': 4}\n",
        "df_processed['Education_Level_Encoded'] = df_processed['Education_Level'].map(edu_mapping)\n",
        "\n",
        "# Social Support Mapping\n",
        "support_mapping = {'Very Low': 1, 'Low': 2, 'Medium': 3, 'High': 4}\n",
        "df_processed['Social_Support_Encoded'] = df_processed['Social_Support'].map(support_mapping)\n",
        "\n",
        "# Risk Level Mapping (Variable Cible)\n",
        "risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "df_processed['Risk_Level_Encoded'] = df_processed['Risk_Level'].map(risk_mapping)\n",
        "\n",
        "# 5.2 One-Hot Encoding: Encodage des variables Nominales\n",
        "print(\"-> One-Hot Encoding des variables Nominales...\")\n",
        "nominal_vars = ['Gender', 'Employment_Status', 'Coping_Mechanism']\n",
        "# Utiliser get_dummies sur le DataFrame traité\n",
        "df_encoded = pd.get_dummies(df_processed, columns=nominal_vars, drop_first=True) \n",
        "\n",
        "# 5.3 Cleanup: Suppression des colonnes originales (textuelles ou ID)\n",
        "cols_to_drop = ['Education_Level', 'Social_Support', 'Risk_Level', 'User_ID']\n",
        "df_final = df_encoded.drop(columns=cols_to_drop)\n",
        "\n",
        "print(\"\\nPremières 5 lignes après encodage (vérifiez les nouvelles colonnes):\")\n",
        "print(df_final.head())\n",
        "print(f\"Taille après encodage: {df_final.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Feature Scaling and Save (Standardisation et Sauvegarde)\n",
        "\n",
        "Sauvegarder le dataset prétraité dans un nouveau fichier CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Données prétraitées sauvegardées dans 'preprocessed_mental_health_data.csv'\n",
            "\n",
            "==================================================\n",
            "--- Step 6: Standardisation des variables et Sauvegarde ---\n",
            "-> Standardisation (Scaling) des variables quantitatives...\n",
            "\n",
            "Statistiques des variables après Standardisation (Moyenne ≈ 0, Écart-type ≈ 1):\n",
            "               Age  Work_Hours_Week  Sleep_Hours_Night  Exercise_Freq_Week  \\\n",
            "mean  1.827110e-16     7.105427e-17       1.644399e-16        2.639159e-17   \n",
            "std   1.000143e+00     1.000143e+00       1.000143e+00        1.000143e+00   \n",
            "\n",
            "       GAD-7_Score   PHQ-9_Score  Stress_Level_Scale  \n",
            "mean  5.379824e-17  4.567775e-17        1.098804e-16  \n",
            "std   1.000143e+00  1.000143e+00        1.000143e+00  \n",
            "\n",
            "Colonnes du DataFrame FINAL prêt pour le Machine Learning:\n",
            "['Age', 'Work_Hours_Week', 'Sleep_Hours_Night', 'Exercise_Freq_Week', 'GAD-7_Score', 'PHQ-9_Score', 'Stress_Level_Scale', 'Education_Level_Encoded', 'Social_Support_Encoded', 'Risk_Level_Encoded', 'Gender_Male', 'Gender_Non-binary', 'Gender_Other', 'Employment_Status_Retired', 'Employment_Status_Self-employed', 'Employment_Status_Student', 'Employment_Status_Unemployed', 'Coping_Mechanism_Gaming', 'Coping_Mechanism_Isolation', 'Coping_Mechanism_Mindfulness', 'Coping_Mechanism_Reading', 'Coping_Mechanism_Socializing', 'Coping_Mechanism_Work']\n",
            "\n",
            "==================================================\n",
            "✅ Données prétraitées et prêtes pour le ML sauvegardées dans 'HealthMind_Preprocessed_Data.csv'\n",
            "Format final: (3500, 23)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Sauvegarder le dataset prétraité\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "\n",
        "\n",
        "df_encoded.to_csv('preprocessed_mental_health_data.csv', index=False)\n",
        "print(\"\\nDonnées prétraitées sauvegardées dans 'preprocessed_mental_health_data.csv'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 6: Standardisation des variables et Sauvegarde ---\")\n",
        "\n",
        "# 6.1 Scaling: Standardisation des variables quantitatives\n",
        "print(\"-> Standardisation (Scaling) des variables quantitatives...\")\n",
        "scaling_vars = ['Age', 'Work_Hours_Week', 'Sleep_Hours_Night', 'Exercise_Freq_Week', \n",
        "                'GAD-7_Score', 'PHQ-9_Score', 'Stress_Level_Scale']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Appliquer la standardisation\n",
        "df_final[scaling_vars] = scaler.fit_transform(df_final[scaling_vars])\n",
        "\n",
        "print(\"\\nStatistiques des variables après Standardisation (Moyenne ≈ 0, Écart-type ≈ 1):\")\n",
        "print(df_final[scaling_vars].describe().loc[['mean', 'std']])\n",
        "\n",
        "# 6.2 Final Check: Afficher les colonnes finales\n",
        "print(\"\\nColonnes du DataFrame FINAL prêt pour le Machine Learning:\")\n",
        "print(df_final.columns.tolist())\n",
        "\n",
        "# 6.3 Save: Sauvegarder le dataset prétraité\n",
        "OUTPUT_FILE = 'HealthMind_Preprocessed_Data.csv'\n",
        "df_final.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"✅ Données prétraitées et prêtes pour le ML sauvegardées dans '{OUTPUT_FILE}'\")\n",
        "print(f\"Format final: {df_final.shape}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "Le \"Mental Health Dataset\" a été prétraité à travers les étapes suivantes :\n",
        "1. Chargement du dataset depuis le fichier CSV spécifié.\n",
        "2. Exploration des colonnes, types de données et statistiques descriptives.\n",
        "3. Identification des variables qualitatives (toutes les colonnes sauf `Timestamp`) et quantitatives (aucune pour l’instant).\n",
        "4. Gestion des valeurs manquantes :\n",
        "   - Suppression des lignes avec valeurs manquantes pour `df1` et `df2`.\n",
        "   - Imputation des valeurs manquantes dans `self_employed` pour `df3` avec la mode.\n",
        "5. Encodage des variables catégoriques nominales (`Gender`, `Country`, `Occupation`) avec one-hot encoding.\n",
        "6. Sauvegarde des données prétraitées dans un fichier CSV.\n",
        "\n",
        "Chaque étape est modulaire et peut être exécutée indépendamment après le chargement des données."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
